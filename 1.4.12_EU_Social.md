

```python
import pandas as pd
import numpy as np
from scipy import stats

file = 'C:\\Users\\Abe\\Data Science Bootcamp\\European Social Data\\ESSdata_Thinkful.csv'
df = pd.read_csv(file, dtype={'idno':int})

df.notnull().sum() * 100 / df.shape[0]
```




    cntry      100.000000
    idno       100.000000
    year       100.000000
    tvtot       99.906912
    ppltrst     99.837096
    pplfair     99.546195
    pplhlp      99.709099
    happy       99.639283
    sclmeet     99.825460
    sclact      98.906214
    gndr        99.883640
    agea        97.218990
    partner     99.802188
    dtype: float64




```python
df.head(10)
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cntry</th>
      <th>idno</th>
      <th>year</th>
      <th>tvtot</th>
      <th>ppltrst</th>
      <th>pplfair</th>
      <th>pplhlp</th>
      <th>happy</th>
      <th>sclmeet</th>
      <th>sclact</th>
      <th>gndr</th>
      <th>agea</th>
      <th>partner</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>CH</td>
      <td>5</td>
      <td>6</td>
      <td>3.0</td>
      <td>3.0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>60.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1</th>
      <td>CH</td>
      <td>25</td>
      <td>6</td>
      <td>6.0</td>
      <td>5.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>9.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>59.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>2</th>
      <td>CH</td>
      <td>26</td>
      <td>6</td>
      <td>1.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>24.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>3</th>
      <td>CH</td>
      <td>28</td>
      <td>6</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>10.0</td>
      <td>6.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>64.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4</th>
      <td>CH</td>
      <td>29</td>
      <td>6</td>
      <td>5.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>55.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>5</th>
      <td>CH</td>
      <td>36</td>
      <td>6</td>
      <td>4.0</td>
      <td>6.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>NaN</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>6</th>
      <td>CH</td>
      <td>40</td>
      <td>6</td>
      <td>3.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>76.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>7</th>
      <td>CH</td>
      <td>41</td>
      <td>6</td>
      <td>2.0</td>
      <td>4.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>30.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>8</th>
      <td>CH</td>
      <td>51</td>
      <td>6</td>
      <td>2.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>9.0</td>
      <td>6.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>84.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>9</th>
      <td>CH</td>
      <td>53</td>
      <td>6</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>62.0</td>
      <td>1.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
df[df['ppltrst'].isnull()]
```




<div>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>cntry</th>
      <th>idno</th>
      <th>year</th>
      <th>tvtot</th>
      <th>ppltrst</th>
      <th>pplfair</th>
      <th>pplhlp</th>
      <th>happy</th>
      <th>sclmeet</th>
      <th>sclact</th>
      <th>gndr</th>
      <th>agea</th>
      <th>partner</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>1645</th>
      <td>CZ</td>
      <td>1101</td>
      <td>6</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>9.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>70.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>1809</th>
      <td>CZ</td>
      <td>1268</td>
      <td>6</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>7.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>68.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1849</th>
      <td>CZ</td>
      <td>1308</td>
      <td>6</td>
      <td>6.0</td>
      <td>NaN</td>
      <td>8.0</td>
      <td>6.0</td>
      <td>10.0</td>
      <td>5.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>46.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1857</th>
      <td>CZ</td>
      <td>1316</td>
      <td>6</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>2.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>29.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>1872</th>
      <td>CZ</td>
      <td>1331</td>
      <td>6</td>
      <td>5.0</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>4.0</td>
      <td>8.0</td>
      <td>3.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>60.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2149</th>
      <td>CZ</td>
      <td>2097</td>
      <td>6</td>
      <td>6.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>1.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>16.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2170</th>
      <td>CZ</td>
      <td>2118</td>
      <td>6</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>8.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>2.0</td>
      <td>56.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>2513</th>
      <td>CZ</td>
      <td>1314</td>
      <td>7</td>
      <td>0.0</td>
      <td>NaN</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>0.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>45.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>4409</th>
      <td>ES</td>
      <td>814</td>
      <td>7</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>5.0</td>
      <td>5.0</td>
      <td>8.0</td>
      <td>7.0</td>
      <td>1.0</td>
      <td>2.0</td>
      <td>80.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>4891</th>
      <td>ES</td>
      <td>1921</td>
      <td>7</td>
      <td>1.0</td>
      <td>NaN</td>
      <td>4.0</td>
      <td>4.0</td>
      <td>7.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>33.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>5521</th>
      <td>NO</td>
      <td>10836</td>
      <td>6</td>
      <td>3.0</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>NaN</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>1.0</td>
      <td>80.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>6602</th>
      <td>NO</td>
      <td>18678</td>
      <td>7</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>NaN</td>
      <td>9.0</td>
      <td>7.0</td>
      <td>4.0</td>
      <td>2.0</td>
      <td>90.0</td>
      <td>2.0</td>
    </tr>
    <tr>
      <th>6902</th>
      <td>SE</td>
      <td>499</td>
      <td>6</td>
      <td>4.0</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>8.0</td>
      <td>9.0</td>
      <td>6.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>71.0</td>
      <td>1.0</td>
    </tr>
    <tr>
      <th>7627</th>
      <td>SE</td>
      <td>3561</td>
      <td>6</td>
      <td>7.0</td>
      <td>NaN</td>
      <td>10.0</td>
      <td>0.0</td>
      <td>5.0</td>
      <td>7.0</td>
      <td>3.0</td>
      <td>2.0</td>
      <td>19.0</td>
      <td>2.0</td>
    </tr>
  </tbody>
</table>
</div>




```python
# Did people become less trusting from 2012 to 2014? Compute results for each country in the sample.

# Create a subset data frame with only relevant columns
df_ss = df[['cntry', 'year', 'idno', 'ppltrst']]

# ID numbers are duplicated. Group duplicate ID numbers 
df_ss = df_ss.groupby(['idno', 'year'], as_index=False).mean()

# Create a df with a country for each ID number
df_country = df[['cntry', 'idno']].drop_duplicates()

# Split subset dataframe into 2 individual dfs for year 2012 and 2014
df6 = df_ss[df_ss['year'] == 6]
df7 = df_ss[df_ss['year'] == 7]

# INNER JOIN the separated data frames on the ID number and then JOIN country for each ID number
df_paired = df6.merge(df7[['idno','ppltrst']], on='idno', suffixes=('_6', '_7')).merge(df_country)

# Drop all ID numbers which have a missing entry in either year
df_paired.dropna(inplace = True)

# Run a dependant T-test for each country in the paired df
for country, subset in df_paired.groupby('cntry'):
    print (country)
    print (stats.ttest_rel(subset['ppltrst_6'], subset['ppltrst_7']))
```

    CH
    Ttest_relResult(statistic=-0.41149118238155802, pvalue=0.68082661688137613)
    CZ
    Ttest_relResult(statistic=-0.62709247710145799, pvalue=0.53081713717334011)
    DE
    Ttest_relResult(statistic=-0.18399501804849683, pvalue=0.85685637970958051)
    ES
    Ttest_relResult(statistic=2.5091340287739454, pvalue=0.012232400751095248)
    NO
    Ttest_relResult(statistic=0.50730770811244041, pvalue=0.61209257015187668)
    SE
    Ttest_relResult(statistic=-2.1537879291079185, pvalue=0.031519997924035682)
    


```python
# Did people become happier from 2012 to 2014? Compute results for each country in the sample.

# Create a subset data frame with relevant columns
df_ss = df[['cntry', 'idno','year','happy']]

# Group data frame to remove duplicate ID numbers per year
df_ss = df_ss.groupby(['idno','year'], as_index=False).mean()

# Split subset data frame into two for each year
df6 = df_ss[df_ss['year'] == 6]
df7 = df_ss[df_ss['year'] == 7]

# Merge two groups on ID Number and then merge in countries on ID Number
df_grouped = df6.merge(df7[['happy','idno']], on='idno', suffixes=('_6','_7')).merge(df_country)
# Drop all rows with missing data
df_grouped.dropna(inplace=True)

for country, group in df_grouped.groupby('cntry'):
    print('{}'.format(country))
    print(stats.ttest_rel(group['happy_6'],group['happy_7']))
```

    CH
    Ttest_relResult(statistic=0.15497577494192596, pvalue=0.87688102912091548)
    CZ
    Ttest_relResult(statistic=-0.44532992184700149, pvalue=0.65622961886460485)
    DE
    Ttest_relResult(statistic=-0.80622577482985491, pvalue=0.43461387077349911)
    ES
    Ttest_relResult(statistic=0.89136887369756856, pvalue=0.37290837524788534)
    NO
    Ttest_relResult(statistic=4.2856826576235925, pvalue=2.0674530134057013e-05)
    SE
    Ttest_relResult(statistic=-0.91818115391649235, pvalue=0.35876866836701093)
    


```python
# Who reported watching more TV in 2012, men or women?

df_ss = df[['gndr','tvtot','year']]
df_ss.dropna(inplace=True)
df_ss = df_ss[df_ss['year'] == 6]
df_ss.loc[df_ss['gndr'] == 1, 'gndr'] = 'M'
df_ss.loc[df_ss['gndr'] == 2, 'gndr'] = 'F'


df_grouped = df_ss.groupby('gndr', as_index=False).mean()
print (df_grouped)

print (stats.ttest_ind(df_ss[df_ss['gndr'] == 'F']['tvtot'],
                       df_ss[df_ss['gndr'] == 'M']['tvtot']))
```

      gndr     tvtot  year
    0    F  3.944393     6
    1    M  3.901906     6
    Ttest_indResult(statistic=0.68999281092095022, pvalue=0.49023604026969858)
    

    c:\users\abe\appdata\local\programs\python\python36-32\lib\site-packages\ipykernel\__main__.py:4: SettingWithCopyWarning: 
    A value is trying to be set on a copy of a slice from a DataFrame
    
    See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy
    


```python
# Who was more likely to believe people were fair in 2012, people living with a partner or people living alone?

df_ss = df[['partner','pplfair','year']]
df6 = df_ss[df_ss['year'] == 6]
df6 = df6[['partner', 'pplfair']]
df6.dropna(inplace=True)

df_grouped = df6.groupby('partner',as_index=False).mean()

print (stats.ttest_ind(df6[df6['partner'] == 1]['pplfair'],
                       df6[df6['partner'] == 2]['pplfair']))
print (df_grouped)
```

    Ttest_indResult(statistic=3.3201033970362084, pvalue=0.00090739526098837563)
       partner   pplfair
    0      1.0  6.080736
    1      2.0  5.856965
    


```python
# Pick three or four of the countries in the sample and compare how often people met socially in 2014. 
# Are there differences, and if so, which countries stand out?

df_ss = df[['cntry','year','sclmeet']]
df7 = df_ss[df_ss['year'] == 7]
df7 = df7[['cntry','sclmeet']]
df7.dropna(inplace=True)

# List of countries: ['CH', 'CZ', 'DE', 'ES', 'NO', 'SE']
country_list = ['CH', 'CZ', 'DE', 'ES', 'NO', 'SE']

df_grouped = df7.groupby('cntry').mean()
df_filtered = df_grouped.filter(items=country_list, axis=0).sort_values('sclmeet', ascending=False)

col = [group['sclmeet'] for country, group in df7.groupby('cntry') if country in country_list]

print (stats.f_oneway(*col))
print (df_filtered)
```

    F_onewayResult(statistic=44.127167288268076, pvalue=1.5708035127828119e-44)
    


```python
#Pick three or four of the countries in the sample and compare how often people took part in social activities,
#relative to others their age, in 2014. Are there differences, and if so, which countries stand out?

df_ss = df[['cntry','year','sclact']]
df7 = df_ss[df_ss['year'] == 7]
df7 = df7[['cntry','sclact']]
df7.dropna(inplace=True)

# List of countries: ['CH', 'CZ', 'DE', 'ES', 'NO', 'SE']
country_list = ['CH', 'CZ', 'DE', 'ES', 'NO', 'SE']

df_grouped = df7.groupby('cntry').mean()
df_filtered = df_grouped.filter(items=country_list, axis=0).sort_values('sclact', ascending=False)

col = [group['sclact'] for country, group in df7.groupby('cntry') if country in country_list]

print (stats.f_oneway(*col))
print (df_filtered)
```

    F_onewayResult(statistic=11.818593033020075, pvalue=2.2490645467328585e-11)
             sclact
    cntry          
    SE     2.879425
    NO     2.859097
    CH     2.781699
    DE     2.714286
    CZ     2.703077
    ES     2.616878
    
